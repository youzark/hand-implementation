{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d85bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from model import ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f153c5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32,padding= 4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "testloader = DataLoader(test, batch_size=128,shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "676fc6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n",
      "256 64\n",
      "256 64\n",
      "256 128\n",
      "512 128\n",
      "512 128\n",
      "512 128\n",
      "512 256\n",
      "1024 256\n",
      "1024 256\n",
      "1024 256\n",
      "1024 256\n",
      "1024 256\n",
      "1024 512\n",
      "2048 512\n",
      "2048 512\n"
     ]
    }
   ],
   "source": [
    "#  Model\n",
    "ResNet50Config = [\n",
    "    {\"in_channels\":64,\"out_channels\":256,\"repetition\":3,\"stride\":1},\n",
    "    {\"in_channels\":256,\"out_channels\":512,\"repetition\":4,\"stride\":2},\n",
    "    {\"in_channels\":512,\"out_channels\":1024,\"repetition\":6,\"stride\":2},\n",
    "    {\"in_channels\":1024,\"out_channels\":2048,\"repetition\":3,\"stride\":2},\n",
    "]\n",
    "resnet = ResNet(ResNet50Config,len(classes)).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6ef9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [1, 100](epoch, minibatch):  11.597118349075318\n",
      "Loss [1, 200](epoch, minibatch):  2.864073600769043\n",
      "Loss [1, 300](epoch, minibatch):  2.280476472377777\n",
      "Loss [2, 100](epoch, minibatch):  1.9106721556186677\n",
      "Loss [2, 200](epoch, minibatch):  1.8278814589977264\n",
      "Loss [2, 300](epoch, minibatch):  1.785675663948059\n",
      "Loss [3, 100](epoch, minibatch):  1.713610795736313\n",
      "Loss [3, 200](epoch, minibatch):  1.6760454726219178\n",
      "Loss [3, 300](epoch, minibatch):  1.64459455370903\n",
      "Loss [4, 100](epoch, minibatch):  1.632245546579361\n",
      "Loss [4, 200](epoch, minibatch):  1.5825051426887513\n",
      "Loss [4, 300](epoch, minibatch):  1.5564600443840027\n",
      "Loss [5, 100](epoch, minibatch):  1.5502659368515015\n",
      "Loss [5, 200](epoch, minibatch):  1.4980029487609863\n",
      "Loss [5, 300](epoch, minibatch):  1.5032159960269929\n",
      "Loss [6, 100](epoch, minibatch):  1.4675427889823913\n",
      "Loss [6, 200](epoch, minibatch):  1.460001267194748\n",
      "Loss [6, 300](epoch, minibatch):  1.4490349721908569\n",
      "Loss [7, 100](epoch, minibatch):  1.419531899690628\n",
      "Loss [7, 200](epoch, minibatch):  1.4054346776008606\n",
      "Loss [7, 300](epoch, minibatch):  1.391608647108078\n",
      "Loss [8, 100](epoch, minibatch):  1.3748445057868957\n",
      "Loss [8, 200](epoch, minibatch):  1.3505769503116607\n",
      "Loss [8, 300](epoch, minibatch):  1.3485936450958251\n",
      "Loss [9, 100](epoch, minibatch):  1.3233388757705689\n",
      "Loss [9, 200](epoch, minibatch):  1.307590503692627\n",
      "Loss [9, 300](epoch, minibatch):  1.3073161554336548\n",
      "Loss [10, 100](epoch, minibatch):  1.278641746044159\n",
      "Loss [10, 200](epoch, minibatch):  1.284571043252945\n",
      "Loss [10, 300](epoch, minibatch):  1.3034198451042176\n",
      "Loss [11, 100](epoch, minibatch):  1.2826860237121582\n",
      "Loss [11, 200](epoch, minibatch):  1.2651301407814026\n",
      "Loss [11, 300](epoch, minibatch):  1.2617823958396912\n",
      "Loss [12, 100](epoch, minibatch):  1.2314103335142135\n",
      "Loss [12, 200](epoch, minibatch):  1.1916899061203003\n",
      "Loss [12, 300](epoch, minibatch):  1.2037249171733857\n",
      "Loss [13, 100](epoch, minibatch):  1.1889512145519257\n",
      "Loss [13, 200](epoch, minibatch):  1.1703463649749757\n",
      "Loss [13, 300](epoch, minibatch):  1.1520411360263825\n",
      "Loss [14, 100](epoch, minibatch):  1.1508402329683305\n",
      "Loss [14, 200](epoch, minibatch):  1.1419125908613206\n",
      "Loss [14, 300](epoch, minibatch):  1.1164031946659088\n",
      "Loss [15, 100](epoch, minibatch):  1.1199734169244766\n",
      "Loss [15, 200](epoch, minibatch):  1.086873430609703\n",
      "Loss [15, 300](epoch, minibatch):  1.078547031879425\n",
      "Loss [16, 100](epoch, minibatch):  1.1383771425485611\n",
      "Loss [16, 200](epoch, minibatch):  1.1057199734449386\n",
      "Loss [16, 300](epoch, minibatch):  1.091926835179329\n",
      "Loss [17, 100](epoch, minibatch):  1.2381130474805833\n",
      "Loss [17, 200](epoch, minibatch):  1.1570583701133728\n",
      "Loss [17, 300](epoch, minibatch):  1.1012602925300599\n",
      "Loss [18, 100](epoch, minibatch):  1.0707957500219345\n",
      "Loss [18, 200](epoch, minibatch):  1.06069096326828\n",
      "Loss [18, 300](epoch, minibatch):  1.0555921471118928\n",
      "Loss [19, 100](epoch, minibatch):  1.0141671001911163\n",
      "Loss [19, 200](epoch, minibatch):  0.9971878081560135\n",
      "Loss [19, 300](epoch, minibatch):  1.0002679872512816\n",
      "Loss [20, 100](epoch, minibatch):  0.9689671468734741\n",
      "Loss [20, 200](epoch, minibatch):  1.0038512647151947\n",
      "Loss [20, 300](epoch, minibatch):  0.9597519761323929\n",
      "Loss [21, 100](epoch, minibatch):  0.9364476329088212\n",
      "Loss [21, 200](epoch, minibatch):  0.9216018134355545\n",
      "Loss [21, 300](epoch, minibatch):  0.9206019169092179\n",
      "Loss [22, 100](epoch, minibatch):  0.9145121300220489\n",
      "Loss [22, 200](epoch, minibatch):  0.8993327397108078\n",
      "Loss [22, 300](epoch, minibatch):  0.9162574899196625\n",
      "Loss [23, 100](epoch, minibatch):  0.9074884682893753\n",
      "Loss [23, 200](epoch, minibatch):  0.8653679412603378\n",
      "Loss [23, 300](epoch, minibatch):  0.8806836134195328\n",
      "Loss [24, 100](epoch, minibatch):  0.88193392932415\n",
      "Loss [24, 200](epoch, minibatch):  0.8541612654924393\n",
      "Loss [24, 300](epoch, minibatch):  0.8530709648132324\n",
      "Loss [25, 100](epoch, minibatch):  0.8165474128723145\n",
      "Loss [25, 200](epoch, minibatch):  0.8193250697851181\n",
      "Loss [25, 300](epoch, minibatch):  0.8314979547262191\n",
      "Loss [26, 100](epoch, minibatch):  0.795100713968277\n",
      "Loss [26, 200](epoch, minibatch):  0.8173604744672776\n",
      "Loss [26, 300](epoch, minibatch):  0.8127209633588791\n",
      "Loss [27, 100](epoch, minibatch):  0.7899325746297836\n",
      "Loss [27, 200](epoch, minibatch):  0.7756512188911437\n",
      "Loss [27, 300](epoch, minibatch):  0.8157410871982574\n",
      "Loss [28, 100](epoch, minibatch):  0.7810103052854538\n",
      "Loss [28, 200](epoch, minibatch):  0.7712323772907257\n",
      "Loss [28, 300](epoch, minibatch):  0.7786089980602264\n",
      "Loss [29, 100](epoch, minibatch):  0.7671192932128906\n",
      "Loss [29, 200](epoch, minibatch):  0.7631685620546341\n",
      "Loss [29, 300](epoch, minibatch):  0.761121335029602\n",
      "Loss [30, 100](epoch, minibatch):  0.7719287985563278\n",
      "Loss [30, 200](epoch, minibatch):  0.7417226654291152\n",
      "Loss [30, 300](epoch, minibatch):  0.7358319860696793\n",
      "Loss [31, 100](epoch, minibatch):  0.7116824966669083\n",
      "Loss [31, 200](epoch, minibatch):  0.7333714133501053\n",
      "Loss [31, 300](epoch, minibatch):  0.7205081796646118\n",
      "Loss [32, 100](epoch, minibatch):  0.7266575747728348\n",
      "Loss [32, 200](epoch, minibatch):  0.7173815941810608\n",
      "Loss [32, 300](epoch, minibatch):  0.7218934226036072\n",
      "Loss [33, 100](epoch, minibatch):  0.7177267843484878\n",
      "Loss [33, 200](epoch, minibatch):  0.788184084892273\n",
      "Loss [33, 300](epoch, minibatch):  0.7397120225429535\n",
      "Loss [34, 100](epoch, minibatch):  0.688566093146801\n",
      "Loss [34, 200](epoch, minibatch):  0.6955949479341507\n",
      "Loss [34, 300](epoch, minibatch):  0.7033104306459427\n",
      "Loss [35, 100](epoch, minibatch):  0.6629875499010086\n",
      "Loss [35, 200](epoch, minibatch):  0.6577626448869706\n",
      "Loss [35, 300](epoch, minibatch):  0.6762552922964096\n",
      "Loss [36, 100](epoch, minibatch):  0.6650825247168541\n",
      "Loss [36, 200](epoch, minibatch):  0.644897716641426\n",
      "Loss [36, 300](epoch, minibatch):  0.661582912504673\n",
      "Loss [37, 100](epoch, minibatch):  0.6801930904388428\n",
      "Loss [37, 200](epoch, minibatch):  0.6440768346190453\n",
      "Loss [37, 300](epoch, minibatch):  0.6416191631555557\n",
      "Loss [38, 100](epoch, minibatch):  0.6364742609858512\n",
      "Loss [38, 200](epoch, minibatch):  0.6258193036913872\n",
      "Loss [38, 300](epoch, minibatch):  0.6268362879753113\n",
      "Loss [39, 100](epoch, minibatch):  0.6078258717060089\n",
      "Loss [39, 200](epoch, minibatch):  0.6138737404346466\n",
      "Loss [39, 300](epoch, minibatch):  0.6376748409867287\n",
      "Loss [40, 100](epoch, minibatch):  0.613659695982933\n",
      "Loss [40, 200](epoch, minibatch):  0.6237050041556358\n",
      "Loss [40, 300](epoch, minibatch):  0.6307627615332604\n",
      "Loss [41, 100](epoch, minibatch):  0.6132992622256279\n",
      "Loss [41, 200](epoch, minibatch):  0.595679053068161\n",
      "Loss [41, 300](epoch, minibatch):  0.595910792350769\n",
      "Loss [42, 100](epoch, minibatch):  0.5831318959593773\n",
      "Loss [42, 200](epoch, minibatch):  0.5903630754351616\n",
      "Loss [42, 300](epoch, minibatch):  0.5909643593430519\n",
      "Loss [43, 100](epoch, minibatch):  0.5717819333076477\n",
      "Loss [43, 200](epoch, minibatch):  0.5879001811146736\n",
      "Loss [43, 300](epoch, minibatch):  0.5908277267217636\n",
      "Loss [44, 100](epoch, minibatch):  0.5864937841892243\n",
      "Loss [44, 200](epoch, minibatch):  0.5665403932332993\n",
      "Loss [44, 300](epoch, minibatch):  0.5885747554898262\n",
      "Loss [45, 100](epoch, minibatch):  0.5553152287006378\n",
      "Loss [45, 200](epoch, minibatch):  0.5825897607207299\n",
      "Loss [45, 300](epoch, minibatch):  0.5601735308766365\n",
      "Loss [46, 100](epoch, minibatch):  0.5632685026526452\n",
      "Loss [46, 200](epoch, minibatch):  0.5568892166018486\n",
      "Loss [46, 300](epoch, minibatch):  0.5871246257424354\n",
      "Loss [47, 100](epoch, minibatch):  0.5583076694607735\n",
      "Loss [47, 200](epoch, minibatch):  0.5510798540711402\n",
      "Loss [47, 300](epoch, minibatch):  0.5744797441363335\n",
      "Loss [48, 100](epoch, minibatch):  0.5564531567692756\n",
      "Loss [48, 200](epoch, minibatch):  0.531849953532219\n",
      "Loss [48, 300](epoch, minibatch):  0.5391003108024597\n",
      "Loss [49, 100](epoch, minibatch):  0.5365544459223748\n",
      "Loss [49, 200](epoch, minibatch):  0.5485571038722992\n",
      "Loss [49, 300](epoch, minibatch):  0.5534022179245949\n",
      "Loss [50, 100](epoch, minibatch):  0.5340706038475037\n",
      "Loss [50, 200](epoch, minibatch):  0.5343133068084717\n",
      "Loss [50, 300](epoch, minibatch):  0.5372249320149421\n",
      "Loss [51, 100](epoch, minibatch):  0.5623963335156441\n",
      "Loss [51, 200](epoch, minibatch):  0.5416653344035148\n",
      "Loss [51, 300](epoch, minibatch):  0.531712244451046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [52, 100](epoch, minibatch):  0.528058898448944\n",
      "Loss [52, 200](epoch, minibatch):  0.5560274419188499\n",
      "Loss [52, 300](epoch, minibatch):  0.5285498562455178\n",
      "Loss [53, 100](epoch, minibatch):  0.5201211223006248\n",
      "Loss [53, 200](epoch, minibatch):  0.52774623721838\n",
      "Loss [53, 300](epoch, minibatch):  0.5943925359845161\n",
      "Loss [54, 100](epoch, minibatch):  0.5180696535110474\n",
      "Loss [54, 200](epoch, minibatch):  0.5361387419700623\n",
      "Loss [54, 300](epoch, minibatch):  0.522774170935154\n",
      "Loss [55, 100](epoch, minibatch):  0.5113767465949058\n",
      "Loss [55, 200](epoch, minibatch):  0.5149204495549202\n",
      "Loss [55, 300](epoch, minibatch):  0.5202765461802482\n",
      "Loss [56, 100](epoch, minibatch):  0.5110090309381485\n",
      "Loss [56, 200](epoch, minibatch):  0.5018356102705002\n",
      "Loss [56, 300](epoch, minibatch):  0.5140234851837158\n",
      "Loss [57, 100](epoch, minibatch):  0.4890895840525627\n",
      "Loss [57, 200](epoch, minibatch):  0.5114451947808266\n",
      "Loss [57, 300](epoch, minibatch):  0.5094378739595413\n",
      "Loss [58, 100](epoch, minibatch):  0.476071240901947\n",
      "Loss [58, 200](epoch, minibatch):  0.5030448967218399\n",
      "Loss [58, 300](epoch, minibatch):  0.5032021129131317\n",
      "Loss [59, 100](epoch, minibatch):  0.4735874351859093\n",
      "Loss [59, 200](epoch, minibatch):  0.48861172288656235\n",
      "Loss [59, 300](epoch, minibatch):  0.49859297901391986\n",
      "Loss [60, 100](epoch, minibatch):  0.488619404733181\n",
      "Loss [60, 200](epoch, minibatch):  0.4804383903741837\n",
      "Loss [60, 300](epoch, minibatch):  0.49450849652290346\n",
      "Loss [61, 100](epoch, minibatch):  0.4747416353225708\n",
      "Loss [61, 200](epoch, minibatch):  0.4918682771921158\n",
      "Loss [61, 300](epoch, minibatch):  0.4842416325211525\n",
      "Loss [62, 100](epoch, minibatch):  0.467736114859581\n",
      "Loss [62, 200](epoch, minibatch):  0.48232599675655363\n",
      "Loss [62, 300](epoch, minibatch):  0.4787426698207855\n",
      "Loss [63, 100](epoch, minibatch):  0.46870839774608614\n",
      "Loss [63, 200](epoch, minibatch):  0.4789178928732872\n",
      "Loss [63, 300](epoch, minibatch):  0.4728677922487259\n",
      "Loss [64, 100](epoch, minibatch):  0.4726909404993057\n",
      "Loss [64, 200](epoch, minibatch):  0.4759452882409096\n",
      "Loss [64, 300](epoch, minibatch):  0.4730347993969917\n",
      "Loss [65, 100](epoch, minibatch):  0.4758254963159561\n",
      "Loss [65, 200](epoch, minibatch):  0.45267685145139697\n",
      "Loss [65, 300](epoch, minibatch):  0.4740916106104851\n",
      "Loss [66, 100](epoch, minibatch):  0.4509233546257019\n",
      "Loss [66, 200](epoch, minibatch):  0.463913094997406\n",
      "Loss [66, 300](epoch, minibatch):  0.4642965880036354\n",
      "Loss [67, 100](epoch, minibatch):  0.4426818007230759\n",
      "Loss [67, 200](epoch, minibatch):  0.4651299378275871\n",
      "Loss [67, 300](epoch, minibatch):  0.4510110878944397\n",
      "Loss [68, 100](epoch, minibatch):  0.4484683296084404\n",
      "Loss [68, 200](epoch, minibatch):  0.46015823185443877\n",
      "Loss [68, 300](epoch, minibatch):  0.4576938433945179\n",
      "Loss [69, 100](epoch, minibatch):  0.45786632269620897\n",
      "Loss [69, 200](epoch, minibatch):  0.45371551483869554\n",
      "Loss [69, 300](epoch, minibatch):  0.4609511706233025\n",
      "Loss [70, 100](epoch, minibatch):  0.44199355721473693\n",
      "Loss [70, 200](epoch, minibatch):  0.4346639585494995\n",
      "Loss [70, 300](epoch, minibatch):  0.4585321590304375\n",
      "Loss [71, 100](epoch, minibatch):  0.4384355518221855\n",
      "Loss [71, 200](epoch, minibatch):  0.4491420093178749\n",
      "Loss [71, 300](epoch, minibatch):  0.44453599691390994\n",
      "Loss [72, 100](epoch, minibatch):  0.4306309452652931\n",
      "Loss [72, 200](epoch, minibatch):  0.4515657961368561\n",
      "Loss [72, 300](epoch, minibatch):  0.44506132245063784\n",
      "Loss [73, 100](epoch, minibatch):  0.4428970721364021\n",
      "Loss [73, 200](epoch, minibatch):  0.43005625158548355\n",
      "Loss [73, 300](epoch, minibatch):  0.46054576635360717\n",
      "Loss [74, 100](epoch, minibatch):  0.42341317772865295\n",
      "Loss [74, 200](epoch, minibatch):  0.4492720013856888\n",
      "Loss [74, 300](epoch, minibatch):  0.4241815847158432\n",
      "Loss [75, 100](epoch, minibatch):  0.4227015222609043\n",
      "Loss [75, 200](epoch, minibatch):  0.4311046288907528\n",
      "Loss [75, 300](epoch, minibatch):  0.44647175520658494\n",
      "Loss [76, 100](epoch, minibatch):  0.422486552298069\n",
      "Loss [76, 200](epoch, minibatch):  0.4256099899113178\n",
      "Loss [76, 300](epoch, minibatch):  0.4371736490726471\n",
      "Loss [77, 100](epoch, minibatch):  0.4055766443908215\n",
      "Loss [77, 200](epoch, minibatch):  0.43737888768315314\n",
      "Loss [77, 300](epoch, minibatch):  0.4440836718678474\n",
      "Loss [78, 100](epoch, minibatch):  0.42772776648402216\n",
      "Loss [78, 200](epoch, minibatch):  0.43345532596111297\n",
      "Loss [78, 300](epoch, minibatch):  0.42768638864159586\n",
      "Loss [79, 100](epoch, minibatch):  0.42967514753341673\n",
      "Loss [79, 200](epoch, minibatch):  0.4077106377482414\n",
      "Loss [79, 300](epoch, minibatch):  0.42378354430198667\n",
      "Loss [80, 100](epoch, minibatch):  0.4133567976951599\n",
      "Loss [80, 200](epoch, minibatch):  0.4192882142961025\n",
      "Loss [80, 300](epoch, minibatch):  0.4388219565153122\n",
      "Loss [81, 100](epoch, minibatch):  0.4340799401700497\n",
      "Loss [81, 200](epoch, minibatch):  0.4367623460292816\n",
      "Loss [81, 300](epoch, minibatch):  0.4251684322953224\n",
      "Loss [82, 100](epoch, minibatch):  0.4110129025578499\n",
      "Loss [82, 200](epoch, minibatch):  0.4169558638334274\n",
      "Loss [82, 300](epoch, minibatch):  0.4301530833542347\n",
      "Loss [83, 100](epoch, minibatch):  0.4034817250072956\n",
      "Loss [83, 200](epoch, minibatch):  0.42158412978053095\n",
      "Loss [83, 300](epoch, minibatch):  0.41760026395320893\n",
      "Loss [84, 100](epoch, minibatch):  0.39208709508180617\n",
      "Loss [84, 200](epoch, minibatch):  0.41910588562488554\n",
      "Loss [84, 300](epoch, minibatch):  0.41849640920758246\n",
      "Loss [85, 100](epoch, minibatch):  0.40737912520766256\n",
      "Loss [85, 200](epoch, minibatch):  0.3925295142829418\n",
      "Loss [85, 300](epoch, minibatch):  0.4125300560891628\n",
      "Loss [86, 100](epoch, minibatch):  0.40633020490407945\n",
      "Loss [86, 200](epoch, minibatch):  0.40055661886930466\n",
      "Loss [86, 300](epoch, minibatch):  0.4184799689054489\n",
      "Loss [87, 100](epoch, minibatch):  0.3921541079878807\n",
      "Loss [87, 200](epoch, minibatch):  0.4022015580534935\n",
      "Loss [87, 300](epoch, minibatch):  0.41084022223949435\n",
      "Loss [88, 100](epoch, minibatch):  0.4057181864976883\n",
      "Loss [88, 200](epoch, minibatch):  0.40730922281742094\n",
      "Loss [88, 300](epoch, minibatch):  0.40435939803719523\n",
      "Loss [89, 100](epoch, minibatch):  0.37421889916062356\n",
      "Loss [89, 200](epoch, minibatch):  0.40252652689814566\n",
      "Loss [89, 300](epoch, minibatch):  0.4019783382117748\n",
      "Loss [90, 100](epoch, minibatch):  0.38578539475798607\n",
      "Loss [90, 200](epoch, minibatch):  0.3818837207555771\n",
      "Loss [90, 300](epoch, minibatch):  0.40267512798309324\n",
      "Loss [91, 100](epoch, minibatch):  0.3714604838192463\n",
      "Loss [91, 200](epoch, minibatch):  0.3841908749938011\n",
      "Loss [91, 300](epoch, minibatch):  0.41659633710980415\n",
      "Loss [92, 100](epoch, minibatch):  0.3894183814525604\n",
      "Loss [92, 200](epoch, minibatch):  0.40790474250912667\n",
      "Loss [92, 300](epoch, minibatch):  0.38804427593946456\n",
      "Loss [93, 100](epoch, minibatch):  0.38038050681352614\n",
      "Loss [93, 200](epoch, minibatch):  0.39160997450351714\n",
      "Loss [93, 300](epoch, minibatch):  0.3919818235933781\n",
      "Loss [94, 100](epoch, minibatch):  0.3880616204440594\n",
      "Loss [94, 200](epoch, minibatch):  0.3869293221831322\n",
      "Loss [94, 300](epoch, minibatch):  0.3908268317580223\n",
      "Loss [95, 100](epoch, minibatch):  0.369734879732132\n",
      "Loss [95, 200](epoch, minibatch):  0.38954226300120354\n",
      "Loss [95, 300](epoch, minibatch):  0.39623691886663437\n",
      "Loss [96, 100](epoch, minibatch):  0.37528928607702255\n",
      "Loss [96, 200](epoch, minibatch):  0.38761965990066527\n",
      "Loss [96, 300](epoch, minibatch):  0.39556977778673175\n",
      "Loss [97, 100](epoch, minibatch):  0.3744396997988224\n",
      "Loss [97, 200](epoch, minibatch):  0.38858923137187956\n",
      "Loss [97, 300](epoch, minibatch):  0.36798406288027763\n",
      "Loss [98, 100](epoch, minibatch):  0.37601465702056885\n",
      "Loss [98, 200](epoch, minibatch):  0.37945656836032865\n",
      "Loss [98, 300](epoch, minibatch):  0.3759837131202221\n",
      "Loss [99, 100](epoch, minibatch):  0.35544446036219596\n",
      "Loss [99, 200](epoch, minibatch):  0.39022757440805433\n",
      "Loss [99, 300](epoch, minibatch):  0.3983528456091881\n",
      "Loss [100, 100](epoch, minibatch):  0.3676486748456955\n",
      "Loss [100, 200](epoch, minibatch):  0.3768146869540214\n",
      "Loss [100, 300](epoch, minibatch):  0.3780475464463234\n",
      "Loss [101, 100](epoch, minibatch):  0.35893206536769867\n",
      "Loss [101, 200](epoch, minibatch):  0.3883569580316544\n",
      "Loss [101, 300](epoch, minibatch):  0.39185729712247847\n",
      "Loss [102, 100](epoch, minibatch):  0.3615646912157536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [102, 200](epoch, minibatch):  0.37317051261663436\n",
      "Loss [102, 300](epoch, minibatch):  0.38156033903360365\n",
      "Loss [103, 100](epoch, minibatch):  0.37098626777529714\n",
      "Loss [103, 200](epoch, minibatch):  0.3703548565506935\n",
      "Loss [103, 300](epoch, minibatch):  0.35786140233278274\n",
      "Loss [104, 100](epoch, minibatch):  0.36499194175004956\n",
      "Loss [104, 200](epoch, minibatch):  0.3775705170631409\n",
      "Loss [104, 300](epoch, minibatch):  0.36030038580298424\n",
      "Loss [105, 100](epoch, minibatch):  0.37266183957457544\n",
      "Loss [105, 200](epoch, minibatch):  0.37969438821077345\n",
      "Loss [105, 300](epoch, minibatch):  0.37497862726449965\n",
      "Loss [106, 100](epoch, minibatch):  0.3527610473334789\n",
      "Loss [106, 200](epoch, minibatch):  0.35570802450180056\n",
      "Loss [106, 300](epoch, minibatch):  0.3836536107957363\n",
      "Loss [107, 100](epoch, minibatch):  0.339065717458725\n",
      "Loss [107, 200](epoch, minibatch):  0.37012856394052507\n",
      "Loss [107, 300](epoch, minibatch):  0.3742829164862633\n",
      "Loss [108, 100](epoch, minibatch):  0.3447384299337864\n",
      "Loss [108, 200](epoch, minibatch):  0.37353944033384323\n",
      "Loss [108, 300](epoch, minibatch):  0.3622005094587803\n",
      "Loss [109, 100](epoch, minibatch):  0.35272750645875933\n",
      "Loss [109, 200](epoch, minibatch):  0.3635456585884094\n",
      "Loss [109, 300](epoch, minibatch):  0.3844296087324619\n",
      "Loss [110, 100](epoch, minibatch):  0.3704171074926853\n",
      "Loss [110, 200](epoch, minibatch):  0.36491303831338884\n",
      "Loss [110, 300](epoch, minibatch):  0.35788210064172743\n",
      "Loss [111, 100](epoch, minibatch):  0.369518081843853\n",
      "Loss [111, 200](epoch, minibatch):  0.3509071035683155\n",
      "Loss [111, 300](epoch, minibatch):  0.3697254505753517\n",
      "Loss [112, 100](epoch, minibatch):  0.36054454669356345\n",
      "Loss [112, 200](epoch, minibatch):  0.379347722530365\n",
      "Loss [112, 300](epoch, minibatch):  0.370193517357111\n",
      "Loss [113, 100](epoch, minibatch):  0.2801286049187183\n",
      "Loss [113, 200](epoch, minibatch):  0.22601763322949409\n",
      "Loss [113, 300](epoch, minibatch):  0.22011692002415656\n",
      "Loss [114, 100](epoch, minibatch):  0.1966314958781004\n",
      "Loss [114, 200](epoch, minibatch):  0.19399523183703424\n",
      "Loss [114, 300](epoch, minibatch):  0.18532042488455772\n",
      "Loss [115, 100](epoch, minibatch):  0.1699861128628254\n",
      "Loss [115, 200](epoch, minibatch):  0.1719518018513918\n",
      "Loss [115, 300](epoch, minibatch):  0.17346552297472953\n",
      "Loss [116, 100](epoch, minibatch):  0.16437055833637715\n",
      "Loss [116, 200](epoch, minibatch):  0.15944379061460495\n",
      "Loss [116, 300](epoch, minibatch):  0.16334590412676334\n",
      "Loss [117, 100](epoch, minibatch):  0.15433169823139906\n",
      "Loss [117, 200](epoch, minibatch):  0.1483423765003681\n",
      "Loss [117, 300](epoch, minibatch):  0.1548864461481571\n",
      "Loss [118, 100](epoch, minibatch):  0.14503604341298343\n",
      "Loss [118, 200](epoch, minibatch):  0.13553036514669656\n",
      "Loss [118, 300](epoch, minibatch):  0.14697099044919015\n",
      "Loss [119, 100](epoch, minibatch):  0.14391409821808337\n",
      "Loss [119, 200](epoch, minibatch):  0.12695147030055523\n",
      "Loss [119, 300](epoch, minibatch):  0.13965058367699384\n",
      "Loss [120, 100](epoch, minibatch):  0.1283909647911787\n",
      "Loss [120, 200](epoch, minibatch):  0.12755715660750866\n",
      "Loss [120, 300](epoch, minibatch):  0.13581242423504591\n",
      "Loss [121, 100](epoch, minibatch):  0.1191112008690834\n",
      "Loss [121, 200](epoch, minibatch):  0.1187442122027278\n",
      "Loss [121, 300](epoch, minibatch):  0.14050741843879222\n",
      "Loss [122, 100](epoch, minibatch):  0.12509054714813828\n",
      "Loss [122, 200](epoch, minibatch):  0.11872504029422998\n",
      "Loss [122, 300](epoch, minibatch):  0.11731158774346113\n",
      "Loss [123, 100](epoch, minibatch):  0.12418188970535994\n",
      "Loss [123, 200](epoch, minibatch):  0.1103697381913662\n",
      "Loss [123, 300](epoch, minibatch):  0.11562816251069308\n",
      "Loss [124, 100](epoch, minibatch):  0.11978727608919143\n",
      "Loss [124, 200](epoch, minibatch):  0.11386800687760115\n",
      "Loss [124, 300](epoch, minibatch):  0.12065357495099306\n",
      "Loss [125, 100](epoch, minibatch):  0.10739368338137865\n",
      "Loss [125, 200](epoch, minibatch):  0.11070157937705517\n",
      "Loss [125, 300](epoch, minibatch):  0.1141360506042838\n",
      "Loss [126, 100](epoch, minibatch):  0.10760090887546539\n",
      "Loss [126, 200](epoch, minibatch):  0.107460664100945\n",
      "Loss [126, 300](epoch, minibatch):  0.10655986852943897\n",
      "Loss [127, 100](epoch, minibatch):  0.1010251047834754\n",
      "Loss [127, 200](epoch, minibatch):  0.10013660617172718\n",
      "Loss [127, 300](epoch, minibatch):  0.10455660527572036\n",
      "Loss [128, 100](epoch, minibatch):  0.09485392410308123\n",
      "Loss [128, 200](epoch, minibatch):  0.09813835140317678\n",
      "Loss [128, 300](epoch, minibatch):  0.10776304919272661\n",
      "Loss [129, 100](epoch, minibatch):  0.10159037485718728\n",
      "Loss [129, 200](epoch, minibatch):  0.10452218320220709\n",
      "Loss [129, 300](epoch, minibatch):  0.10086457333527506\n",
      "Loss [130, 100](epoch, minibatch):  0.09286221081390977\n",
      "Loss [130, 200](epoch, minibatch):  0.0879994416795671\n",
      "Loss [130, 300](epoch, minibatch):  0.09081501180306077\n",
      "Loss [131, 100](epoch, minibatch):  0.08179402085021138\n",
      "Loss [131, 200](epoch, minibatch):  0.09230071874335408\n",
      "Loss [131, 300](epoch, minibatch):  0.09313411198556423\n",
      "Loss [132, 100](epoch, minibatch):  0.08979061661288142\n",
      "Loss [132, 200](epoch, minibatch):  0.08486935503780842\n",
      "Loss [132, 300](epoch, minibatch):  0.09128783721476794\n",
      "Loss [133, 100](epoch, minibatch):  0.07974919803440571\n",
      "Loss [133, 200](epoch, minibatch):  0.08299260867759585\n",
      "Loss [133, 300](epoch, minibatch):  0.08011133966967464\n",
      "Loss [134, 100](epoch, minibatch):  0.08412305995821953\n",
      "Loss [134, 200](epoch, minibatch):  0.0776492472551763\n",
      "Loss [134, 300](epoch, minibatch):  0.08186699891462922\n",
      "Loss [135, 100](epoch, minibatch):  0.08028763938695192\n",
      "Loss [135, 200](epoch, minibatch):  0.08087574981153012\n",
      "Loss [135, 300](epoch, minibatch):  0.08094756012782454\n",
      "Loss [136, 100](epoch, minibatch):  0.07793241064995528\n",
      "Loss [136, 200](epoch, minibatch):  0.0834071296080947\n",
      "Loss [136, 300](epoch, minibatch):  0.08080029347911477\n",
      "Loss [137, 100](epoch, minibatch):  0.08001561207696796\n",
      "Loss [137, 200](epoch, minibatch):  0.06933873432688414\n",
      "Loss [137, 300](epoch, minibatch):  0.07607007689774037\n",
      "Loss [138, 100](epoch, minibatch):  0.07427321704104543\n",
      "Loss [138, 200](epoch, minibatch):  0.08026766385883093\n",
      "Loss [138, 300](epoch, minibatch):  0.0766063137166202\n",
      "Loss [139, 100](epoch, minibatch):  0.07790839703753591\n",
      "Loss [139, 200](epoch, minibatch):  0.07126153230667115\n",
      "Loss [139, 300](epoch, minibatch):  0.06991800397634507\n",
      "Loss [140, 100](epoch, minibatch):  0.07708310338668525\n",
      "Loss [140, 200](epoch, minibatch):  0.07524858966469765\n",
      "Loss [140, 300](epoch, minibatch):  0.0734822802990675\n",
      "Loss [141, 100](epoch, minibatch):  0.06883527956902981\n",
      "Loss [141, 200](epoch, minibatch):  0.06802091529592871\n",
      "Loss [141, 300](epoch, minibatch):  0.07063411228358746\n",
      "Loss [142, 100](epoch, minibatch):  0.067514557717368\n",
      "Loss [142, 200](epoch, minibatch):  0.06726459132507444\n",
      "Loss [142, 300](epoch, minibatch):  0.07672822376713156\n",
      "Loss [143, 100](epoch, minibatch):  0.06756274662911892\n",
      "Loss [143, 200](epoch, minibatch):  0.06742354460991919\n",
      "Loss [143, 300](epoch, minibatch):  0.06372713549993932\n",
      "Loss [144, 100](epoch, minibatch):  0.06826138224452734\n",
      "Loss [144, 200](epoch, minibatch):  0.0667205593548715\n",
      "Loss [144, 300](epoch, minibatch):  0.06258864370174706\n",
      "Loss [145, 100](epoch, minibatch):  0.06097624507732689\n",
      "Loss [145, 200](epoch, minibatch):  0.06411167584359646\n",
      "Loss [145, 300](epoch, minibatch):  0.06598917811177671\n",
      "Loss [146, 100](epoch, minibatch):  0.06871631311252713\n",
      "Loss [146, 200](epoch, minibatch):  0.06396346936002374\n",
      "Loss [146, 300](epoch, minibatch):  0.066778972633183\n",
      "Loss [147, 100](epoch, minibatch):  0.06609394719824195\n",
      "Loss [147, 200](epoch, minibatch):  0.06566719311289489\n",
      "Loss [147, 300](epoch, minibatch):  0.06658798456192017\n",
      "Loss [148, 100](epoch, minibatch):  0.054021170521155\n",
      "Loss [148, 200](epoch, minibatch):  0.060119906733743844\n",
      "Loss [148, 300](epoch, minibatch):  0.05922591145150363\n",
      "Loss [149, 100](epoch, minibatch):  0.05907108472660184\n",
      "Loss [149, 200](epoch, minibatch):  0.0630023780837655\n",
      "Loss [149, 300](epoch, minibatch):  0.0630201069638133\n",
      "Loss [150, 100](epoch, minibatch):  0.06030430524609983\n",
      "Loss [150, 200](epoch, minibatch):  0.05957535091787577\n",
      "Loss [150, 300](epoch, minibatch):  0.06184858458116651\n",
      "Loss [151, 100](epoch, minibatch):  0.05748195670545101\n",
      "Loss [151, 200](epoch, minibatch):  0.062075556507334116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [151, 300](epoch, minibatch):  0.06104477164335549\n",
      "Loss [152, 100](epoch, minibatch):  0.05466379531659186\n",
      "Loss [152, 200](epoch, minibatch):  0.05452787913382053\n",
      "Loss [152, 300](epoch, minibatch):  0.054464360754936936\n",
      "Loss [153, 100](epoch, minibatch):  0.052376099405810235\n",
      "Loss [153, 200](epoch, minibatch):  0.05768597613088786\n",
      "Loss [153, 300](epoch, minibatch):  0.05997103847563267\n",
      "Loss [154, 100](epoch, minibatch):  0.05858463745564222\n",
      "Loss [154, 200](epoch, minibatch):  0.05670063076540828\n",
      "Loss [154, 300](epoch, minibatch):  0.060091189481317996\n",
      "Loss [155, 100](epoch, minibatch):  0.06298253939021378\n",
      "Loss [155, 200](epoch, minibatch):  0.058118418492376804\n",
      "Loss [155, 300](epoch, minibatch):  0.059695315361022946\n",
      "Loss [156, 100](epoch, minibatch):  0.0502258543856442\n",
      "Loss [156, 200](epoch, minibatch):  0.054710500864312055\n",
      "Loss [156, 300](epoch, minibatch):  0.060102215027436616\n",
      "Loss [157, 100](epoch, minibatch):  0.04879541135393083\n",
      "Loss [157, 200](epoch, minibatch):  0.05220833297818899\n",
      "Loss [157, 300](epoch, minibatch):  0.05490666968747973\n",
      "Loss [158, 100](epoch, minibatch):  0.05235654792748392\n",
      "Loss [158, 200](epoch, minibatch):  0.05122088130563498\n",
      "Loss [158, 300](epoch, minibatch):  0.05215215049684048\n",
      "Loss [159, 100](epoch, minibatch):  0.04978949989192188\n",
      "Loss [159, 200](epoch, minibatch):  0.0524796499684453\n",
      "Loss [159, 300](epoch, minibatch):  0.05267482157796621\n",
      "Loss [160, 100](epoch, minibatch):  0.04649483143351972\n",
      "Loss [160, 200](epoch, minibatch):  0.05255504303611815\n",
      "Loss [160, 300](epoch, minibatch):  0.05442565990611911\n",
      "Loss [161, 100](epoch, minibatch):  0.05346039299853146\n",
      "Loss [161, 200](epoch, minibatch):  0.058790210289880636\n",
      "Loss [161, 300](epoch, minibatch):  0.056079239128157495\n",
      "Loss [162, 100](epoch, minibatch):  0.04580021465197206\n",
      "Loss [162, 200](epoch, minibatch):  0.04636306650005281\n",
      "Loss [162, 300](epoch, minibatch):  0.054043868971057236\n",
      "Loss [163, 100](epoch, minibatch):  0.04885693722870201\n",
      "Loss [163, 200](epoch, minibatch):  0.05185844825580716\n",
      "Loss [163, 300](epoch, minibatch):  0.05656185686122626\n",
      "Loss [164, 100](epoch, minibatch):  0.053001383086666465\n",
      "Loss [164, 200](epoch, minibatch):  0.0525441637262702\n",
      "Loss [164, 300](epoch, minibatch):  0.04896100752055645\n",
      "Loss [165, 100](epoch, minibatch):  0.05082693017087877\n",
      "Loss [165, 200](epoch, minibatch):  0.053171217245981096\n",
      "Loss [165, 300](epoch, minibatch):  0.04925804063212127\n",
      "Loss [166, 100](epoch, minibatch):  0.04858907631598413\n",
      "Loss [166, 200](epoch, minibatch):  0.04858399678952992\n",
      "Loss [166, 300](epoch, minibatch):  0.049991503665223716\n",
      "Loss [167, 100](epoch, minibatch):  0.04363212648779154\n",
      "Loss [167, 200](epoch, minibatch):  0.04785662597976625\n",
      "Loss [167, 300](epoch, minibatch):  0.046537022721022364\n",
      "Loss [168, 100](epoch, minibatch):  0.046339913411065935\n",
      "Loss [168, 200](epoch, minibatch):  0.054266556189395486\n",
      "Loss [168, 300](epoch, minibatch):  0.045650666505098345\n",
      "Loss [169, 100](epoch, minibatch):  0.04769491544924676\n",
      "Loss [169, 200](epoch, minibatch):  0.04501844086684287\n",
      "Loss [169, 300](epoch, minibatch):  0.0511728783743456\n",
      "Loss [170, 100](epoch, minibatch):  0.04416726975701749\n",
      "Loss [170, 200](epoch, minibatch):  0.04544853542000055\n",
      "Loss [170, 300](epoch, minibatch):  0.04743772217072546\n",
      "Loss [171, 100](epoch, minibatch):  0.04490892122965306\n",
      "Loss [171, 200](epoch, minibatch):  0.04906933630350977\n",
      "Loss [171, 300](epoch, minibatch):  0.05279803189449012\n",
      "Loss [172, 100](epoch, minibatch):  0.040676443483680484\n",
      "Loss [172, 200](epoch, minibatch):  0.04860760308802128\n",
      "Loss [172, 300](epoch, minibatch):  0.0479876532452181\n",
      "Loss [173, 100](epoch, minibatch):  0.05167591457255185\n",
      "Loss [173, 200](epoch, minibatch):  0.04608390581328422\n",
      "Loss [173, 300](epoch, minibatch):  0.0475377928186208\n",
      "Loss [174, 100](epoch, minibatch):  0.050614227820187804\n",
      "Loss [174, 200](epoch, minibatch):  0.045410514799878\n",
      "Loss [174, 300](epoch, minibatch):  0.04802444529719651\n",
      "Loss [175, 100](epoch, minibatch):  0.04893946579657495\n",
      "Loss [175, 200](epoch, minibatch):  0.05205606976523995\n",
      "Loss [175, 300](epoch, minibatch):  0.045813595075160266\n",
      "Loss [176, 100](epoch, minibatch):  0.05306401182897389\n",
      "Loss [176, 200](epoch, minibatch):  0.04693685761187225\n",
      "Loss [176, 300](epoch, minibatch):  0.048880254100076855\n",
      "Loss [177, 100](epoch, minibatch):  0.039171543673146514\n",
      "Loss [177, 200](epoch, minibatch):  0.03821977570652962\n",
      "Loss [177, 300](epoch, minibatch):  0.034218761413358154\n",
      "Loss [178, 100](epoch, minibatch):  0.03226395337842405\n",
      "Loss [178, 200](epoch, minibatch):  0.028644370543770493\n",
      "Loss [178, 300](epoch, minibatch):  0.029545169360935687\n",
      "Loss [179, 100](epoch, minibatch):  0.029871854721568523\n",
      "Loss [179, 200](epoch, minibatch):  0.025772071650717408\n",
      "Loss [179, 300](epoch, minibatch):  0.03163166141370311\n",
      "Loss [180, 100](epoch, minibatch):  0.028038115042727442\n",
      "Loss [180, 200](epoch, minibatch):  0.02497109117684886\n",
      "Loss [180, 300](epoch, minibatch):  0.026069431705400346\n",
      "Loss [181, 100](epoch, minibatch):  0.027614714677911253\n",
      "Loss [181, 200](epoch, minibatch):  0.022495119366794825\n",
      "Loss [181, 300](epoch, minibatch):  0.024464036470744757\n",
      "Loss [182, 100](epoch, minibatch):  0.025660779592581093\n",
      "Loss [182, 200](epoch, minibatch):  0.026416805032640697\n",
      "Loss [182, 300](epoch, minibatch):  0.022021690716501327\n",
      "Loss [183, 100](epoch, minibatch):  0.021227288553491236\n",
      "Loss [183, 200](epoch, minibatch):  0.02629725526785478\n",
      "Loss [183, 300](epoch, minibatch):  0.020951589809264988\n",
      "Loss [184, 100](epoch, minibatch):  0.024784018201753497\n",
      "Loss [184, 200](epoch, minibatch):  0.021944894497282805\n",
      "Loss [184, 300](epoch, minibatch):  0.023246664886828514\n",
      "Loss [185, 100](epoch, minibatch):  0.023248637760989368\n",
      "Loss [185, 200](epoch, minibatch):  0.0233827275573276\n",
      "Loss [185, 300](epoch, minibatch):  0.021258033353369683\n",
      "Loss [186, 100](epoch, minibatch):  0.020048397136852147\n",
      "Loss [186, 200](epoch, minibatch):  0.021171103345695882\n",
      "Loss [186, 300](epoch, minibatch):  0.020775042136665433\n",
      "Loss [187, 100](epoch, minibatch):  0.02407090428401716\n",
      "Loss [187, 200](epoch, minibatch):  0.021488066667225213\n",
      "Loss [187, 300](epoch, minibatch):  0.018826896434184164\n",
      "Loss [188, 100](epoch, minibatch):  0.023034858878236263\n",
      "Loss [188, 200](epoch, minibatch):  0.01997828239691444\n",
      "Loss [188, 300](epoch, minibatch):  0.019761260668747126\n",
      "Loss [189, 100](epoch, minibatch):  0.02152938534040004\n",
      "Loss [189, 200](epoch, minibatch):  0.020438591288402676\n",
      "Loss [189, 300](epoch, minibatch):  0.01934943113476038\n",
      "Loss [190, 100](epoch, minibatch):  0.020258814757689834\n",
      "Loss [190, 200](epoch, minibatch):  0.02103248271159828\n",
      "Loss [190, 300](epoch, minibatch):  0.017310147306416182\n",
      "Loss [191, 100](epoch, minibatch):  0.0175229163444601\n",
      "Loss [191, 200](epoch, minibatch):  0.017132845050655307\n",
      "Loss [191, 300](epoch, minibatch):  0.018998849347699433\n",
      "Loss [192, 100](epoch, minibatch):  0.02159372580703348\n",
      "Loss [192, 200](epoch, minibatch):  0.018894428396597506\n",
      "Loss [192, 300](epoch, minibatch):  0.01966463456628844\n",
      "Loss [193, 100](epoch, minibatch):  0.01774407796910964\n",
      "Loss [193, 200](epoch, minibatch):  0.019840099988505243\n",
      "Loss [193, 300](epoch, minibatch):  0.017408012757077814\n",
      "Loss [194, 100](epoch, minibatch):  0.018083037320757285\n",
      "Loss [194, 200](epoch, minibatch):  0.019756244618911296\n",
      "Loss [194, 300](epoch, minibatch):  0.019246545026544482\n",
      "Loss [195, 100](epoch, minibatch):  0.01931055973051116\n",
      "Loss [195, 200](epoch, minibatch):  0.016596266932319848\n",
      "Loss [195, 300](epoch, minibatch):  0.019338174087461083\n",
      "Loss [196, 100](epoch, minibatch):  0.01861731580225751\n",
      "Loss [196, 200](epoch, minibatch):  0.019831010927446185\n",
      "Loss [196, 300](epoch, minibatch):  0.015560776576166972\n",
      "Loss [197, 100](epoch, minibatch):  0.01689500089036301\n",
      "Loss [197, 200](epoch, minibatch):  0.017607157621532678\n",
      "Loss [197, 300](epoch, minibatch):  0.01655893107294105\n",
      "Loss [198, 100](epoch, minibatch):  0.014221027402672917\n",
      "Loss [198, 200](epoch, minibatch):  0.01913544901413843\n",
      "Loss [198, 300](epoch, minibatch):  0.016968323660548776\n",
      "Loss [199, 100](epoch, minibatch):  0.016642773277126252\n",
      "Loss [199, 200](epoch, minibatch):  0.016106838017003612\n",
      "Loss [199, 300](epoch, minibatch):  0.018658518306910992\n",
      "Loss [200, 100](epoch, minibatch):  0.019763813191093504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [200, 200](epoch, minibatch):  0.018024649765575305\n",
      "Loss [200, 300](epoch, minibatch):  0.016658030939288436\n"
     ]
    }
   ],
   "source": [
    "# Train Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)\n",
    "\n",
    "EPOCHS=200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for index, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        logits = resnet(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if index%100 == 0 and index > 0:\n",
    "            print(f'Loss [{epoch+1}, {index}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b41285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10,000 test images:  85.61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = resnet(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on 10,000 test images: ', 100*(correct/total), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69107612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
